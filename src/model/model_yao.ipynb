{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Input, Embedding, Dense, TimeDistributed, Concatenate, Attention\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.seq2seq import AttentionWrapper\n",
    "import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../../preprocessed_oh.npz')\n",
    "text_vec = data['text_word2vec']\n",
    "summary_vec = data['summary_word2vec']\n",
    "text_existence = data['text_existence']\n",
    "text_count = data['text_count']\n",
    "summary_existence = data['summary_existence']\n",
    "summary_count = data['summary_count']\n",
    "labels = data[\"labels\"]\n",
    "text_voc_size = data['text_voc_size']\n",
    "sum_voc_size = data['sum_voc_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an attention mechanism\n",
    "https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(keras.layers.Layer):\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name = \"att_weight\", shape = (input_shape[-1],1))\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        inputs: x = [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        et = K.squeeze(K.tanh(K.dot(x,self.W)+ self.b), axis = -1)\n",
    "        at = K.expand_dims(K.softmax(et), axis = -1)\n",
    "        output = x*at\n",
    "        return K.sum(output,axis =1)\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we build up the Encoder-Decoder architecture using LSTM model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 1000\n",
    "\n",
    "#https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\n",
    "def create_model(max_text_len,x_voc_size, hidden_size):\n",
    "    #Encoder\n",
    "    encoder_input = Input(shape=(max_text_len,))\n",
    "    enc_emb = Embedding(x_voc_size, hidden_size,trainable=True)(encoder_input) \n",
    "    \n",
    "    enc_lstm1 = LSTM(hidden_size, return_sequences = True, return_state = True)\n",
    "    encoder_out1, state_h1, state_c1 = enc_lstm1(enc_emb)\n",
    "    \n",
    "    enc_lstm2 = LSTM(hidden_size, return_sequences = True, return_state = True)\n",
    "    encoder_out2, state_h2, state_c2 = enc_lstm2(enc_emb)\n",
    "    \n",
    "    enc_lstm3 = LSTM(hidden_size, return_sequences = True, return_state = True)\n",
    "    encoder_out3, state_h3, state_c3 = enc_lstm3(enc_emb)\n",
    "    \n",
    "    decoder_input = Input(shape = (None,))\n",
    "    dec_emb_layer = Embedding(y_voc_size, hidden_size, trainable = True)\n",
    "    dec_emb = dec_emb_layer(decoder_input) \n",
    "    \n",
    "    dec_lstm = LSTM(hidden_size, return_sequences=True, return_state=True) \n",
    "    dec_outputs,decoder_fwd_state, decoder_back_state = dec_lstm(dec_emb,initial_state=[state_h3, state_c3]) \n",
    "    \n",
    "\n",
    "    print(f\"dec_outputs: {np.shape(dec_outputs)} encoder_out3: {np.shape(encoder_out3)}\")\n",
    "    attention_out = Attention()([encoder_out3,dec_outputs])\n",
    "    decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([dec_outputs, attention_out])\n",
    "    decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax'))  \n",
    "    decoder_outputs = decoder_dense(decoder_concat_input)   \n",
    "    model =Model([encoder_input, decoder_input],decoder_outputs)\n",
    "    model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy')\n",
    "    return model\n",
    "#attention = AttentionWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dec_outputs: (None, None, 1000) encoder_out3: (None, 20000, 1000)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 20000)]      0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 20000, 1000)  11866000    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 1000)   11866000    ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 20000, 1000  8004000     ['embedding[0][0]']              \n",
      "                                ),                                                                \n",
      "                                 (None, 1000),                                                    \n",
      "                                 (None, 1000)]                                                    \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 1000)  8004000     ['embedding_1[0][0]',            \n",
      "                                , (None, 1000),                   'lstm_2[0][1]',                 \n",
      "                                 (None, 1000)]                    'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 20000, 1000)  0           ['lstm_2[0][0]',                 \n",
      "                                                                  'lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)     (None, 20000, 2000)  0           ['lstm_3[0][0]',                 \n",
      "                                                                  'attention[0][0]']              \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 20000, 11866  23743866   ['concat_layer[0][0]']           \n",
      " ted)                           )                                                                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 63,483,866\n",
      "Trainable params: 63,483,866\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(max_text_len,x_voc_size, hidden_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1287, 20000) (1287, 200)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/users/eleves-b/2020/yufei.liu/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/users/eleves-b/2020/yufei.liu/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/users/eleves-b/2020/yufei.liu/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/users/eleves-b/2020/yufei.liu/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/users/eleves-b/2020/yufei.liu/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/users/eleves-b/2020/yufei.liu/.local/lib/python3.8/site-packages/keras/backend.py\", line 3313, in concatenate\n        return tf.concat([to_dense(x) for x in tensors], axis)\n\n    ValueError: Exception encountered when calling layer \"concat_layer\" (type Concatenate).\n    \n    Dimension 1 in both shapes must be equal, but are 199 and 20000. Shapes are [?,199] and [?,20000]. for '{{node model/concat_layer/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](model/lstm_3/PartitionedCall:1, model/attention/MatMul_1, model/concat_layer/concat/axis)' with input shapes: [?,199,1000], [?,20000,1000], [] and with computed input tensors: input[2] = <2>.\n    \n    Call arguments received:\n      • inputs=['tf.Tensor(shape=(None, 199, 1000), dtype=float32)', 'tf.Tensor(shape=(None, 20000, 1000), dtype=float32)']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d775efc89135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/users/eleves-b/2020/yufei.liu/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/users/eleves-b/2020/yufei.liu/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/users/eleves-b/2020/yufei.liu/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/users/eleves-b/2020/yufei.liu/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/users/eleves-b/2020/yufei.liu/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/users/eleves-b/2020/yufei.liu/.local/lib/python3.8/site-packages/keras/backend.py\", line 3313, in concatenate\n        return tf.concat([to_dense(x) for x in tensors], axis)\n\n    ValueError: Exception encountered when calling layer \"concat_layer\" (type Concatenate).\n    \n    Dimension 1 in both shapes must be equal, but are 199 and 20000. Shapes are [?,199] and [?,20000]. for '{{node model/concat_layer/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](model/lstm_3/PartitionedCall:1, model/attention/MatMul_1, model/concat_layer/concat/axis)' with input shapes: [?,199,1000], [?,20000,1000], [] and with computed input tensors: input[2] = <2>.\n    \n    Call arguments received:\n      • inputs=['tf.Tensor(shape=(None, 199, 1000), dtype=float32)', 'tf.Tensor(shape=(None, 20000, 1000), dtype=float32)']\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "history=model.fit([x_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=512, validation_data=([x_test,y_test[:,:-1]], y_test.reshape(y_test.shape[0],y_test.shape[1], 1)[:,1:]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c30f2af5f468e7f5b45bcc30fca5f4886c90d54777aed916ed5f6294dfb24bf2"
  },
  "kernelspec": {
   "display_name": "CSE204",
   "language": "python",
   "name": "cse204"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
